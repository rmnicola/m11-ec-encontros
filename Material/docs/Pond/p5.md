---
title: P5 - Inferência em paralelo (CPU)
sidebar_position: 5
sidebar_class_name: ponderada
---

# Paralelismo no forward pass (CPU)

**Atividade com prazo para 08/10/2024 às 23h59**

:::warning

Essa ponderada constrói complexidade em cima da ponderada 4. Isso significa que
você obrigatoriamente precisa fazer a P4 para fazer essa atividade? Não, mas o
escopo da P5 (essa atividade) contempla também o escopo da P4. Sendo assim,
seria um pouco mais eficiente se você decidisse entregar as duas juntas.
Leia-se: uma nota 10 aqui implica, obrigatoriamente, em uma nota 10 na P4.

:::

Quando trabalhamos com alguns tipos de tarefas computacionais, é quase uma
obrigação moral utilizar paralelismo. Deep learning é uma dessas tarefas.
Tipicamente, utilizamos paralelismo utilizando GPUs para tarefas de deep
learning, mas o paralelismo *original* foi utilizando sistemas distribuídos
focados em CPUs.

Trabalhar com processamento paralelo em CPUs é uma questão de compartilhamento
eficiente de memória e ser capaz de resolver os problemas que surgem quando
recursos computacionais concorrem pelo acesso à mesma memória. Existem algumas
ferramentas para ajudar a resolver esses problemas. Entre elas, as mais antigas
envolvem o uso de linguagens de sistema como C e C++. São elas o *OpenMP* e o
*MPI*.

Adivinha? Você vai pegar o seu framework de inferência desenvolvido na P4 e
adicionar paralelismo com CPU usando *uma linguagem de sistema*.

## 1. Enunciado

Em breve

## 2. Padrão de qualidade

Em breve
